---
title: "STAT 4620 Final Project"
output: pdf_document
date: "2025-12-14"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Import Libraries
library(tidyverse)
library(rpart)
library(rpart.plot)
library(caret)
library(pROC)
library(class)
library(pls)
library(glmnet)
```

```{r}
# Setup and Import Data
set.seed(4620)
train <- read.csv("data/train.csv")
test <- read.csv("data/test.csv")
```

# EDA

```{r}

```

# Model Analysis

## Classification/Regression Tree
```{r}
# Setup Classification Data
train_class <- train
test_class <- test

train_class$Bankrupt. <- factor(train_class$Bankrupt.)
test_class$Bankrupt. <- factor(test_class$Bankrupt.)

predictor_cols <- setdiff(colnames(train_class), "Bankrupt.")
```

```{r}
# Apply CART Model
cart_full <- rpart(
  formula = as.formula(paste("Bankrupt. ~", paste(predictor_cols, collapse = " + "))),
  data = train_class,
  method = "class",
  cp = 0.0001,
  minsplit = 5
)
```

```{r}
# Examine Output
printcp(cart_full)
plotcp(cart_full)
```

```{r}
# Find Optimal Value For Pruning
cptable <- cart_full$cptable
min_row <- which.min(cptable[,"xerror"])

xerr_min <- cptable[min_row,"xerror"]
xerr_SE  <- cptable[min_row,"xstd"]

threshold <- xerr_min + xerr_SE
opt_row <- which(cptable[,"xerror"] <= threshold)[1]
opt_cp <- cptable[opt_row,"CP"]
```

```{r}
# Prune Tree
cart_pruned <- prune(cart_full, cp = opt_cp)

cart_pruned$variable.importance
```

```{r}
# Plot Updated Tree
rpart.plot(
  cart_pruned,
  type = 2,
  fallen.leaves = TRUE,
  extra = 104,
  main = "Pruned CART Tree"
)
```

```{r}
# Predict on Test Data
pred_probs_class <- predict(cart_pruned, newdata = test, type = "prob")[,2]
pred_class_class <- factor(ifelse(pred_probs_class > 0.5, "1", "0"), levels = c("0","1"))

conf_mat_class <- confusionMatrix(pred_class_class, test_class$Bankrupt.)
conf_mat_class

accuracy_class <- conf_mat_class$overall["Accuracy"]
sensitivity_class <- conf_mat_class$byClass["Sensitivity"]
specificity_class <- conf_mat_class$byClass["Specificity"]

accuracy_class
sensitivity_class
specificity_class
```

## KNN
```{r}
# Setup KNN Data
train_knn <- train
test_knn <- test

train_knn$Bankrupt. <- factor(train_knn$Bankrupt.)
test_knn$Bankrupt. <- factor(test_knn$Bankrupt.)

predictor_cols <- setdiff(colnames(train), c("Bankrupt.", "Unnamed..0"))
```

```{r}
# Standardize Predictors
preproc <- preProcess(train[, predictor_cols], method = c("center", "scale"))

train_scaled <- predict(preproc, train_knn[, predictor_cols])
test_scaled <- predict(preproc, test_knn[, predictor_cols])
```

```{r}
# Find Best K Value
K_values <- seq(1, 51, by = 2)
acc_results <- c()

for (k in K_values) {
  knn_pred <- knn(
    train = train_scaled,
    test = test_scaled,
    cl = train_knn$Bankrupt.,
    k = k,
    prob = TRUE
  )
  
  acc <- mean(knn_pred == test_knn$Bankrupt.)
  acc_results <- c(acc_results, acc)
}

best_k <- K_values[which.max(acc_results)]
best_k
```

```{r}
# Fit KNN Model and 
knn_pred <- knn(
  train = train_scaled,
  test  = test_scaled,
  cl = train_knn$Bankrupt.,
  k = best_k,
  prob = TRUE
)

conf_mat_knn <- confusionMatrix(knn_pred, test_knn$Bankrupt.)
conf_mat_knn

accuracy_knn <- conf_mat_knn$overall["Accuracy"]
sensitivity_knn <- conf_mat_knn$byClass["Sensitivity"]
specificity_knn <- conf_mat_knn$byClass["Specificity"]

accuracy_knn
sensitivity_knn
specificity_knn
```

# PLS
```{r}
# Setup PLS Data
train_pls <- train
test_pls <- test

train_pls$Bankrupt. <- factor(train_pls$Bankrupt.)
test_pls$Bankrupt. <- factor(test_pls$Bankrupt.)
```

```{r}
# Clean Up Dataset
predictor_cols <- setdiff(colnames(train_pls), c("Bankrupt.", "Unnamed..0"))

X_train_pls <- train_pls[, predictor_cols]
X_test_pls <- test_pls[, predictor_cols]

y_train_pls <- as.numeric(as.character(train_pls$Bankrupt.))
y_test_pls <- as.numeric(as.character(test_pls$Bankrupt.))
```

```{r}
# Fit PLS Model and Find Optimal Components
pls_fit <- plsr(
  y_train_pls ~ as.matrix(X_train_pls),
  scale = TRUE,
  validation = "CV",
  segments = 10
)

plot(RMSEP(pls_fit), main = "PLS CV - RMSEP vs Components")

opt_M <- which.min(RMSEP(pls_fit)$val[1,1,])
opt_M
```

```{r}
# Predict on Test Data With Optimal Components
pls_pred_probs <- predict(pls_fit, newdata = as.matrix(X_test_pls), ncomp = opt_M)

pls_pred_probs <-pls_pred_probs[,1,1]

pls_pred_class <- ifelse(pls_pred_probs > .5, "1", "0")
pls_pred_class<- factor(pls_pred_class, levels = c("0", "1"))
```

```{r}
# Evaluate Performance
conf_mat_pls <- confusionMatrix(pls_pred_class, test_pls$Bankrupt.)
conf_mat_pls

accuracy_pls <- conf_mat_pls$overall["Accuracy"]
sensitivity_pls <- conf_mat_pls$byClass["Sensitivity"]
specificity_pls <- conf_mat_pls$byClass["Specificity"]

accuracy_pls
sensitivity_pls
specificity_pls
```

# Ridge Regression
```{r}
# Setup Ridge Data
train_ridge <- train
test_ridge <- test

y_train_ridge <- as.numeric(as.character(train_ridge$Bankrupt.))
y_test_ridge <- as.numeric(as.character(test_ridge$Bankrupt.))
```

```{r}
# Cleanup Columns
predictor_cols_ridge <- setdiff(colnames(train_ridge), c("Bankrupt.", "Unnamed..0"))

X_train_ridge <- as.matrix(train_ridge[, predictor_cols_ridge])
X_test_ridge <- as.matrix(test_ridge[, predictor_cols_ridge])
```

```{r}
# Fit Ridge Logistic Regression
ridge_cv <- cv.glmnet( 
  x = X_train_ridge, 
  y = y_train_ridge, 
  alpha = 0, 
  family = "binomial", 
  standardize = TRUE, 
  type.measure = "deviance"
)

best_lambda <- ridge_cv$lambda.min
best_lambda
```

```{r}
# Fit Final Ridge Model
ridge_fit <- glmnet(
  x = X_train_ridge,
  y = y_train_ridge,
  alpha = 0,
  family = "binomial",
  lambda = best_lambda,
  standardize = TRUE
)
```

```{r}
# Predict on Test Data
ridge_prob <- predict(ridge_fit, newx = X_test_ridge, type = "response")

ridge_pred <- ifelse(ridge_prob > 0.5, "1", "0")
ridge_pred <- factor(ridge_pred, levels = c("0", "1"))
```

```{r}
# Evaluate Ridge Performance
y_test_factor <- factor(test_ridge$Bankrupt., levels = c("0", "1"))
conf_mat_ridge <- confusionMatrix(ridge_pred, y_test_factor)
conf_mat_ridge

accuracy_ridge <- conf_mat_ridge$overall["Accuracy"]
sensitivity_ridge <- conf_mat_ridge$byClass["Sensitivity"]
specificity_ridge <- conf_mat_ridge$byClass["Specificity"]

accuracy_ridge
sensitivity_ridge
specificity_ridge
```

```{r}
#=============================
# Setup LASSO Data
#=============================

train_lasso <- train
test_lasso  <- test

y_train_lasso <- as.numeric(as.character(train_lasso$Bankrupt.))
y_test_lasso  <- as.numeric(as.character(test_lasso$Bankrupt.))

predictor_cols_lasso <- setdiff(colnames(train_lasso), c("Bankrupt.", "Unnamed..0"))

X_train_lasso <- as.matrix(train_lasso[, predictor_cols_lasso])
X_test_lasso  <- as.matrix(test_lasso[, predictor_cols_lasso])


#=============================
# Fit LASSO Logistic Regression
#=============================

lasso_cv <- cv.glmnet(
  x = X_train_lasso,
  y = y_train_lasso,
  alpha = 1,               # <-- LASSO
  family = "binomial",
  standardize = TRUE,
  type.measure = "deviance"
)

best_lambda_lasso <- lasso_cv$lambda.min
best_lambda_lasso


#=============================
# Fit Final LASSO Model
#=============================

lasso_fit <- glmnet(
  x = X_train_lasso,
  y = y_train_lasso,
  alpha = 1,               # <-- LASSO
  family = "binomial",
  lambda = best_lambda_lasso,
  standardize = TRUE
)


#=============================
# Predict on Test Data
#=============================

lasso_prob <- predict(lasso_fit, newx = X_test_lasso, type = "response")

lasso_pred <- ifelse(lasso_prob > 0.5, "1", "0")
lasso_pred <- factor(lasso_pred, levels = c("0", "1"))


#=============================
# Evaluate LASSO Performance
#=============================

y_test_factor_lasso <- factor(test_lasso$Bankrupt., levels = c("0", "1"))

conf_mat_lasso <- confusionMatrix(lasso_pred, y_test_factor_lasso)
conf_mat_lasso

accuracy_lasso    <- conf_mat_lasso$overall["Accuracy"]
sensitivity_lasso <- conf_mat_lasso$byClass["Sensitivity"]
specificity_lasso <- conf_mat_lasso$byClass["Specificity"]

accuracy_lasso
sensitivity_lasso
specificity_lasso

```

